mysql -u root -p
export PATH=${PATH}:/usr/local/mysql/bin
https://apple.stackexchange.com/questions/176786/how-to-add-mysql-to-path-variable-to-resolve-mysql-command-not-found

ALTER TABLE customer DROP PRIMARY KEY;
ALTER TABLE lineitem DROP PRIMARY KEY;
alter table nation drop primary key;
alter table orders drop primary key;
alter table part drop primary key;
alter table partsupp drop primary key;
alter table region drop primary key;
alter table supplier drop primary key;


with cte(tbl, c) as (
    select 'customer', (select count(*) from customer)
    union all
    select 'lineitem', (select count(*) from lineitem)
    union all
    select 'nation', (select count(*) from nation)
    union all
    select 'orders', (select count(*) from orders)
    union all
    select 'part', (select count(*) from part)
    union all
    select 'partsupp', (select count(*) from partsupp)
    union all
    select 'region', (select count(*) from region)
    union all
    select 'supplier', (select count(*) from supplier)
)
select c.* from cte c where c.c= (select max(c1.c) from cte c1);

password: Gobronxbombers2

TPC-H
    - https://www.metricfire.com/blog/a-modern-guide-to-mysql-performance-monitoring/
    - https://dev.mysql.com/doc/refman/8.0/en/server-status-variables.html
    - https://stackoverflow.com/questions/1733507/how-to-get-size-of-mysql-database
    - https://docs.verdictdb.org/tutorial/tpch/
    - https://www.tpc.org/tpc_documents_current_versions/current_specifications5.asp
    - https://dev.mysql.com/doc/heatwave/en/mys-hw-tpch-quickstart-create-database-import.html

    - https://github.com/Percona-Lab/sysbench-tpcc
    - https://github.com/akopytov/sysbench

    - https://github.com/electrum/tpch-dbgen
    - https://github.com/dhuny/tpch/tree/main VERY USEFUL
    - https://github.com/pola-rs/tpch/tree/700a440212aada40fbe3431591cb19d0cb0b530e VERY USEFUL

    Need to create one additional table:
        create table if not exists revenue0 (supplier_no int, total_revenue int);
        insert into revenue0
            select l_suppkey, sum(l_extendedprice * (1 - l_discount)) from lineitem where l_shipdate >= date '1993-01-01' and l_shipdate < date '1993-01-01' + interval '3' month group by l_suppkey;


Indices:
    - https://stackoverflow.com/questions/14143813/find-out-usage-statistics-of-mysql-indices
    - https://dba.stackexchange.com/questions/20038/how-can-i-tell-if-an-index-is-being-used-to-sort-in-mysql
    - https://stackoverflow.com/questions/31372353/how-to-check-the-query-is-using-the-indexes-in-mysql
    - https://dev.mysql.com/doc/refman/8.0/en/explain-output.html

Knob params: https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html

Loss and gradients:
    - https://stackoverflow.com/questions/73840143/in-pytorch-how-do-i-update-a-neural-network-via-the-average-gradient-from-a-lis
    - https://discuss.pytorch.org/t/how-to-get-gradient-of-loss/16955
    - https://stackoverflow.com/questions/57248777/backward-function-in-pytorch
    - https://stackoverflow.com/questions/65947284/loss-with-custom-backward-function-in-pytorch-exploding-loss-in-simple-mse-exa
    - https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html
    - https://stackoverflow.com/questions/57580202/whats-the-purpose-of-torch-autograd-variable
    

Normalization:
    - https://discuss.pytorch.org/t/best-way-to-normalize-the-input/139557


Output layer activations:
    - https://stackoverflow.com/questions/56415450/how-to-set-up-a-neural-network-so-that-it-have-in-output-only-0-or-1
    - https://datascience.stackexchange.com/questions/92748/how-to-make-a-neural-network-output-a-specific-number-out-of-a-certain-range
    - sigmoid: binary
    - softmax: multiclass
    - both between 0 and 1, however


Notes:
    - created folder "lib" in /usr/local/
    - sudo ln -s /usr/local/mysql/lib/libssl.1.1.dylib /usr/local/lib/libssl.1.1.dylib\n
    - sudo ln -s /usr/local/mysql/lib/libcrypto.1.1.dylib /usr/local/lib/libcrypto.1.1.dylib\n

    - throughput and latency is calculated on the tables in tpcc100
    - need a table tpch for indices work

    - ./tpcc_start -h 127.0.0.1 -d tpcc100 -uroot -p "Gobronxbombers2" -w 10 -c 6 -r 10 -l 30 -i 2 > /Users/jamespetullo/atlastune/tpc/tpcc/performance_outputs/run_test2.txt

    - current database: tpch1 (1GB)
        - see folder "TPC_H_OFFICIAL"

    - Starting indices option: https://github.com/dimitri/tpch-citus/blob/master/schema/tpch-index.sql

    - Idea: using QPH or raw latency from running the queries might take too long in a standard training cycle, however, query cost can be used, but every n cycles, the QPH can be found, and if QPH(i+1) < QPH(i), that is, a drop in overall raw performance, subsequent penalties can be applied to the rewards stored for transitions in the minibatch indexed under the last n cycles. That way, when transitions are sampled, the updated rewards can be used

    - Idea: every n cycles, run the standard latency and throughput tests, and go back into memory buffer and make penalizations if latency and throughput have degraded (i.e too many indices have been created)

    - There might be enough of a positive gradient in the experience replay if most rewards are negative

    - Idea: clip rewards to be between range of -10 and 10
    - Idea: alter tables to remove primary keys
    - Look into using tracxn database
    - Perhaps try TPC-DS?
    - TPC-E?
    - https://github.com/TPC-Council/HammerDB/
    - https://github.com/cmu-db/benchbase
    - TPC-H works?
    - with TPC-H, perhaps clearing out the dummy text blobs did the trick
    - Not every query is equal: more time-intensive queries should have heigher priority than inherently shorter/faster queries, perhaps need weighting 
    - Note: might need to initialize experience replay with self.actor instead of random process?
    